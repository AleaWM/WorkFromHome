---
title: "Work From Home: Who Can and Who Does?"
subtitle: "Using 2021 1-Year ACS Data"
#format: docx

format:
  html:
    toc: true
    toc_float: true
    df-print: paged
---

# Getting Data

```{r setup, warning=FALSE, message=FALSE}

library(scales)
library(reldist)
library(pollster)
library(labelled)
library(weights)
library(tigris)
library(ipumsr)
library(tidyverse)
#install.packages("naniar")
library(naniar)

knitr::opts_chunk$set(warning=FALSE, message=FALSE)
```

## ACS data Notes

IPUMS [link for Survey package](https://usa.ipums.org/usa/repwt.shtml)

Survey questions for EMPSTAT & LABFORCE:

1.  Last week, did this person work for pay at a job or business? (Yes or no) -- Yes becomes coded as EMPSTAT = 1-Employed.
2.  Last week, did this person do ANY work for pay, even as little as one hour?(Yes or no) -- Yes becomes coded as LABFORCE = 2-Yes in the labor force.

Survey questions for INCEARN:

1.  INCEARN = INCWAGE + INCBUS00
    1.  Total amount earned in last 12 months: Wages, salary, commissions, bonuses, tips. \[Yes --\> \_\_\_\_\_\_ \] is coded as INCWAGE value.

        1.  INCWAGE is topcoded only at the 99.5th percentile with a state. So less than 1% of incomes will be coded as a lower value. [Source](https://usa.ipums.org/usa-action/variables/INCWAGE#editing_procedure_section). Not a problem.

    2.  Total amount earned in last 12 months: Self-employment income from own businesses (includes farms, nonfarms, proprietorship, and partnerships). \[Yes --\> \$\_\_\_\_\] is coded as INCBUS00 value.

-   INCEARN includes self-employment income, INCWAGE does not.

    -   INCWAGE does not include Farming income and self-employment income, but INCEARN does.
    -   INCEARN is not itself topcoded but some variables that go into it are slightly topcoded. Shouldn't impact analysis.

`usa_00011.xml` and `usa_00011.dat.gz` are the same as Box files named `IL_2021_1yr_ACS.dat.gz` and `IL_2021_1yr_ACS_datDDI.xml`

> original xml file references the file name that it is called in the download. Either change the XML file to reference the correct .dat.gz files OR just keep track of which extracts are the same as the box file names.

```{r}
# old version with less variables:
#ddi <- read_ipums_ddi("usa_00009.xml") # 45 variables
#data <- read_ipums_micro(ddi) # 126623 observations before any filtering

# larger version with 147 variables. uses same file as Box file named "IL_2021_1yr_ACS.dat.gz and IL_2021_1yr_ACS_datDDI.xml
ddi <- read_ipums_ddi("usa_00011.xml") # downloaded April 10 2023
data <- read_ipums_micro(ddi) # 126623 observations before any filtering

# same sample but with 150+ variables. 
# NEED TO CHANGE XML file that referneces the data file. currently says usa_00011.dat.gz so these two lines of code do not work. 
#ddi <- read_ipums_ddi("C:/Users/aleaw/Box/Fiscal Futures/FY22_Working/WFH/Data/IL_2021_1yrACS_datDDI.xml") # downloaded April 10 2023
#data <- read_ipums_micro(ddi) # 126623 observations before any filtering

data <- data %>% select(INCEARN, INCWAGE, INCTOT, TRANWORK, OCCSOC,CLASSWKR, EMPSTAT, LABFORCE, PERWT, COUNTYFIP, PUMA, PWSTATE2, AGE, STRATA, CLUSTER, RACE, SEX )



# replaces 0 with NA for variables listed. Allows topline to calculate "Valid Percent" when it recognizes missing values

data <- data %>% replace_with_na(replace = list(
  EMPSTAT= c(0), 
  LABFORCE=c(0), 
  CLASSWKR = c(0),
  OCCSOC = c(0),
  TRANWORK = c("N/A","0")))



```

# Xiaoyan replication

126,623 observations originally in ACS 2021 1-year sample.

Note: Dropping groups of people using filter() from the sample will change the standard errors of estimates since it changes the sample size. Use the survey() or svy() command to drop subsets of people (like if we wanted to filter age groups). Google what commands to use to drop observations without impacting standard errors.

```{r}
# Before any filtering, median income is $30,361
summary(as.numeric(data$INCEARN)) 


data25to64 <- data %>% 
  filter(AGE > 24 & AGE < 65)
# 65,675 observations in age range
summary(as.numeric(data25to64$INCEARN)) # median = $36,900


dataXH <- data25to64 %>% filter(LABFORCE == 2)
# 50,817 observations are in labor force and 25-64 years old
summary(as.numeric(dataXH$INCEARN)) # median = $50,000
# Higher than ACS per capita amount, if that matters

dataXH %>% filter(INCEARN >0) %>% summary(as.numeric(INCEARN)) # median = $50,000 still
rm(data25to64)



table(dataXH$RACE)
topline(df = dataXH, variable = RACE, weight = PERWT )

# manually making summary table that has observation counts and weighted estiamtes:
dataXH %>% 
  group_by(as_factor(RACE)) %>%
  dplyr::summarize(weightedcount=sum(PERWT),
                   unweightedcount = n()) %>%  #weighted
  mutate(pct_weighted = round(weightedcount/sum(weightedcount), digits = 3),
         pct_noweight = round(unweightedcount/sum(unweightedcount), digits = 3))
## Matches table() and topline() outputs! That's good. Can use this format to see counts and estimates with percentages all together.


```

Race and sex counts and proportions matches Xiaoyans output from April 22 2023. Yay.

```{r desc-sex}
dataXH %>% 
  group_by(as_factor(SEX)) %>%
  dplyr::summarize(weightedcount=sum(PERWT),
                   unweightedcount = n()) %>%  #weighted
  mutate(pct_weighted = round(weightedcount/sum(weightedcount), digits = 3),
         pct_noweight = round(unweightedcount/sum(unweightedcount), digits = 3))
```

```{r desc-tranwork}
dataXH %>% 
  group_by(as_factor(TRANWORK)) %>%
  dplyr::summarize(weightedcount=sum(PERWT),
                   unweightedcount = n()) %>%  #weighted
  mutate(pct_weighted = round(weightedcount/sum(weightedcount), digits = 3),
         pct_noweight = round(unweightedcount/sum(unweightedcount), digits = 3))

#attributes(dataXH$TRANWORK)
#table(dataXH$TRANWORK)

dataXH <- dataXH %>% 
  mutate(did_wfh = if_else(TRANWORK==80, 1,0)) # 1 = wfh, 0 = did not wfh
# 9,470 observations worked from home
# 37,584 did not work from home.
table(dataXH$did_wfh)

dataXH <- dataXH %>% replace_with_na(replace = list(
  did_wfh= c(NA)))


dataXH %>% 
  group_by(as_factor(did_wfh)) %>%
  dplyr::summarize(weightedcount=sum(PERWT),
                   unweightedcount = n()) %>%  #weighted
  mutate(pct_weighted = round(weightedcount/sum(weightedcount), digits = 3),
         pct_noweight = round(unweightedcount/sum(unweightedcount), digits = 3))

topline(dataXH, did_wfh, weight = PERWT)

```

18.9% of Illinois workers worked at home. 74% went to work using some form of transportation, 7.4% of observations were missing values.

-   Valid percent: 20.5% of observations with responses did WFH and 79.4% of observations with responses did not WFH.

```{r binary-variables-for-tables}
dataXH <- dataXH %>% 
  mutate(
    did_wfh_labels = ifelse(did_wfh == 1, "Did WFH", "Did not WFH"),
    has_incearn = ifelse(INCEARN > 0, 1, 0), ## has earned income = 1
    has_occsoc = ifelse(OCCSOC > 0, 1, 0),# has occupation = 1
    has_incearn_labels = ifelse(INCEARN > 0, "Has EarnInc", "No IncData"), ## has earned income = 1
    has_occsoc_labels = ifelse(OCCSOC > 0, "Has Occ", "No Occ") ## OCCSOC code greater than zero coded as 1
    )
table(dataXH$has_occsoc) # all have occupations after filtering for income, labor force, etc. 



# worked when coded as 0 or 1.
xtabs(did_wfh~has_incearn, data = dataXH)



xtabs(has_occsoc~has_incearn, data = dataXH)
table(dataXH$has_incearn, dataXH$has_occsoc)
table(dataXH$did_wfh, dataXH$has_occsoc)


table(dataXH$did_wfh_labels, dataXH$has_occsoc_labels)
# could apply labels to the variable but I'm lazy. Made two variables instead.
table(dataXH$did_wfh, dataXH$has_incearn)
# 9,464 observations worked from home and have income values
# 37,561 observations did not work from home and have income values.


```

9,464 observations worked from home and have income values.\
37,561 observations did not work from home and have income values.

```{r message = FALSE, warning=FALSE}
telework <- read_csv("teleworkable_AWM.csv")
joined <- left_join(dataXH, telework, by = c("OCCSOC" = "occ_codes"))

table(joined$teleworkable)
hist(joined$teleworkable)

joined <- joined %>% 
  mutate(CanWorkFromHome = case_when(
  teleworkable == 0 ~ "No WFH",
  teleworkable < 1 ~ "Some WFH",
  teleworkable == 1 ~ "Can WFH",
  TRUE ~ "Check Me")
)

library(srvyr)
library(survey)
#as_survey() from srvyr package

dstrata <- joined %>% as_survey(strata = STRATA, 
                                ids = CLUSTER, 
                                weights = PERWT)
class(dstrata)

dstrata <- dstrata %>% 
  mutate(percentile = ntile(INCEARN,100),
         decile = ntile(INCEARN, 10))

inc_quantiles<-survey::svyquantile(~INCEARN, design=dstrata, 
                    quantiles = c(0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1) ,
                    #interval.type = "quantile",
                    na.rm=TRUE, 
                    ci = FALSE 
                    )

inc_quantiles

dstrata

```

#### Gender and Working from home

20.5% of those in the labor force worked from home in 2021.

-   10.7% were women, 9.8% were men.

52.6% of those in the labor force were Men, 47.4% were Women.

> Is this when t-tests are supposed to be used? Comparing two groups but are they actually statistically significantly different?

```{r}

dataXH %>% 
  filter(LABFORCE == 2 &  did_wfh==1) %>%  #9470 people who worked from home and were in the labor force. 
  mutate(total = n())  %>%
  group_by(SEX) %>% 
  dplyr::summarize(n=n())


round(prop.table(svytable(~has_occsoc+SEX, design=dstrata))*100,digits=2)

round(prop.table(svytable(~did_wfh_labels, design=dstrata))*100,digits=2) # 1 is Male, 2 is female

round(prop.table(svytable(~did_wfh_labels+SEX, design=dstrata))*100,digits=2) # 1 is Male, 2 is female


```

#### Income Deciles

```{r}
#| code-fold: TRUE

#min= -8000, max=949000 for INCEARN 
breaks <- c(-8000, 9400, 20000, 30000, 40000, 48000, 60000, 72000, 90000, 124000)
decile_labels <- c("Bottom 10%", "20%", "30%", "40%", "50%", "60%", "70%", "80%", "90%", "Top 10%")
#code from above


summary <- dstrata %>%
  group_by(decile) %>% 
  summarise(min = min(INCEARN),
            max=max(INCEARN),
            avg_income = mean(INCEARN),
            average_income = survey_mean(INCEARN),
            pop_represented = sum(PERWT),
            obs_count = n())

sum(summary$pop_represented)
sum(summary$obs_count)


dstrata %>%
  as_data_frame() %>%
  ggplot(aes(x=decile, 
             y=did_wfh 
             
             )) + 
  geom_col()+
  scale_x_discrete(limits = c("Bottom 10%", "20%", "30%", "40%", "50%", "60%", "70%", "80%", "90%", "Top 10%"))  +
  #scale_y_continuous(labels=percent) +
  labs(x="",y="",
       title = "Count of workers who worked at home by income decile during 2021")






graph<- dstrata %>%
as_data_frame() %>%
 # mutate(total = n()) %>%
  filter(CanWorkFromHome != "Check Me") %>%
  ggplot(aes(x=decile, 
             y = (..count..)/sum(..count..)*10,
             fill = CanWorkFromHome)) + 
  geom_bar( position = "dodge") +
  #coord_flip()+
    theme(legend.position = "bottom") +

  scale_x_discrete(limits = c("Bottom 10%", "20%", "30%", "40%", "50%", "60%", "70%", "80%", "90%", "Top 10%"))+
  scale_y_continuous(labels=scales::percent) +
  labs(x="",y="", title = "2021, 25-64, Labor force, Weighted. Xiaoyan Comparison ")

graph  # +geom_text(aes(label= (..count..)/sum(..count..)*10 ), position = position_dodge(width=1))

dstrata %>%
as_data_frame() %>%
  count(did_wfh, decile) %>%
  mutate(pct = round(n/sum(n)*1000, 1))%>%
  filter(did_wfh == 1)%>%
  #filter(did_wfh == "Can WFH") %>%
  #group_by(decile)%>%
  #summarize(count2 = n()) %>%
  ggplot(aes(x=decile,
             fill = did_wfh,
             y = pct,
            # label = paste0(round(count/sum(count),2)*100,"%")
               #(..count..)/sum(..count..)*10
             )) + 
  geom_col() +
  coord_flip()+
    theme(legend.position = "bottom") +

  scale_x_discrete(limits = c("Bottom 10%", "20%", "30%", "40%", "50%", "60%", "70%", "80%", "90%", "Top 10%"))+
  #scale_y_continuous(labels=scales::percent) +
  geom_text(aes(label=paste0(pct,"%")), hjust=1.3)+
  labs(x="",y="% Worked at Home", title = "Individuals with higher income were more able to work from home",
       caption = "Did work from home is based on ACS variable TRANWORK.")+
  theme_minimal()+
  theme(legend.position = "none")

```

```{r}
#| code-fold: true

dstrata %>%
as_data_frame() %>%
  filter(CanWorkFromHome != "Check Me") %>%
  count(decile, CanWorkFromHome) %>%
  mutate(pct = round(n/sum(n/10), 3)*100)%>%
  ggplot(aes(x=decile, 
             y = n,
         fill = factor(CanWorkFromHome, levels = c("No WFH", "Some WFH",  "Can WFH"))
         )) + 
  geom_bar( stat = "identity") +
  coord_flip()+
  geom_text(aes(label=paste0(pct, "%")), 
            position = position_stack(vjust=0.5), size=3)+
    theme(legend.position = "bottom", legend.title = element_blank()) +

  scale_x_discrete(limits = c("Bottom 10%", "20%", "30%", "40%", "50%", "60%", "70%", "80%", "90%", "Top 10%"))+
    guides(fill = guide_legend(reverse = TRUE))+

  #scale_y_continuous(labels=scales::percent) +
  labs(x="Earned Income Deciles", y="# Survey Responses", 
       title = "Ability to work from home based on occupational characteristics",
       caption = "Occupation data from ACS 1-year 2021 sample. 
       The ability to work from home is based on occupation characteristics from BLS occupation 
       surveys & D&N's paper. Includes workers wo were 25-64 and responded to OCCSOC n=>50,000.")



dstrata %>%
as_data_frame() %>%
  filter(CanWorkFromHome != "Check Me") %>%

  ggplot(aes(x=decile, 
         #    y = (..count..)/sum(..count..)*10,
          
         fill = factor(CanWorkFromHome, levels = c("No WFH", "Some WFH",  "Can WFH"))
         )) + 
  geom_bar( position = "fill") +
  coord_flip()+
  geom_text( aes(label=paste0(signif(..count.. / tapply(..count.., ..x.., sum)[as.character(..x..)], digits=3)*100,"%")),
    stat="count", position = position_fill(vjust=0.5)) +
    theme(legend.position = "bottom", legend.title = element_blank()) +

  scale_x_discrete(limits = c("Bottom 10%", "20%", "30%", "40%", "50%", "60%", "70%", "80%", "90%", "Top 10%"))+
  guides(fill = guide_legend(reverse = TRUE))+
  #scale_y_continuous(labels=scales::percent) +
  labs(x="Earned Income Deciles", y="% Survey Responses", 
       title = "Ability to work from home based on occupational characteristics",
       caption = "Occupation data from ACS 1-year 2021 sample. 
       The ability to work from home is based on occupation characteristics from BLS occupation 
       surveys & D&N's paper. Includes workers who were 25-64 and responded to OCCSOC question. n=>50,000.") 
```

```{r dataXH-graphs}
#| code-fold: TRUE

summary(as.numeric(dataXH$INCEARN))


summary <- dstrata %>% 
  group_by(decile) %>% 
  summarize(min = min(INCEARN),
            max=max(INCEARN),
            avg_income = mean(INCEARN),
            average_income = survey_mean(INCEARN),
            pop_represented = sum(PERWT),
            obs_count = n())
summary %>% 
  ggplot(aes(x=decile, y=average_income, label=scales::dollar(average_income))) + 
  geom_col()+
  scale_x_discrete(limits = c("Bottom 10%", "20%", "30%", "40%", "50%", "60%", "70%", "80%", "90%", "Top 10%"))+
  scale_y_continuous(labels = scales::dollar)+labs(x="",y="", title = "Average earned income for each income decile")+
  geom_text(vjust = -0.5, size = 3)


```

## Francis replication

Using INCEARN and Labor Force workers ages 25-64:

Percentage of WFH workers by income decile in 2019

Percentage of WFH workers by Income decile in 2021.

```{r}
#| code-fold: TRUE
dstrata %>%
  as_data_frame() %>%
#  filter(did_wfh == 1) %>% # did work from home according to TRANWORK ACS question on commuting to work
#  group_by(decile) %>%
  #summarize(avgincearn = survey::svymean(INCEARN, dstrata)) %>%
  #ungroup%>%
  ggplot()+
  geom_col(aes(x=decile, y=did_wfh, group = decile))+coord_flip()

#+scale_x_continuous()
#+

dstrata %>%
as_data_frame() %>%
  ggplot(aes(x=decile, 
           #  y = (..count../sum(..count..)*10), 
             fill = CanWorkFromHome
         )) + 
  geom_bar()+
  coord_flip()+
  #geom_text(aes(label=after_stat(count)), position = position_stack(vjust=0.5), size=3)+
    theme(legend.position = "bottom", legend.title = element_blank()) +
#  geom_text(aes(label = after_stat()))+
  scale_x_discrete(limits = c("Bottom 10%", "20%", "30%", "40%", "50%", "60%", "70%", "80%", "90%", "Top 10%"))+
  labs(x="Earned Income Deciles", y="# Survey Responses", 
       title = "Who did work from home, by income deciles",
       caption = "Occupation data from ACS 1-year 2021 sample. 
       The ability to work from home is based on TRANWORK survey question.. Includes workers wo were 25-64 and responded to TRANWORK n=~47,000.")
```

```{r}

topline(dataXH, did_wfh,  weight=PERWT)
# All members of the labor force could have said they either work from home (TRANWORK=80), go to work using some form of transportation, or didn't answer the question. 8.2% of the labor force did not answer the TRANWORK question and should not be included in calculations.
crosstab(dataXH, x=LABFORCE, y=RACE, weight = PERWT, pct_type = "row", unwt_n=TRUE, n=FALSE)  # matches Francis Total Row in Race output


crosstab(dataXH, x=RACE, y=did_wfh, weight = PERWT, unwt_n=TRUE, n=FALSE)
crosstab(dataXH, x=RACE, y=did_wfh, weight = PERWT, pct_type = "column", unwt_n=TRUE, n=FALSE)
crosstab(dataXH, x=did_wfh, y=RACE, weight = PERWT, pct_type = "row", unwt_n=TRUE, n=FALSE)
crosstab(dataXH, x=did_wfh, y=RACE, weight = PERWT)

crosstab_3way(dataXH, z=LABFORCE, y=did_wfh, x=RACE, weight = PERWT)
crosstab_3way(dataXH, y=LABFORCE, x=did_wfh, z=RACE, weight = PERWT)
crosstab_3way(dataXH, x=RACE, y=did_wfh, z=LABFORCE, weight = PERWT)
crosstab_3way(dataXH, x=RACE, y=did_wfh, z=LABFORCE, weight = PERWT, pct_type = "cell")




```

```{r}
crosstab(dataXH, x=LABFORCE, y=SEX, weight = PERWT, pct_type = "row", unwt_n=TRUE, n=FALSE) # matches Francis, 52% male, 48% female in laborforce
crosstab(dataXH, x=did_wfh, y=SEX, weight = PERWT, pct_type = "row", unwt_n=TRUE, n=FALSE)
crosstab(dataXH, x=SEX, y=did_wfh, weight = PERWT, pct_type = "row", unwt_n=TRUE, n=FALSE)
crosstab_3way(dataXH, x=did_wfh, y=SEX, z=LABFORCE,weight = PERWT, )

```

```{r}
dataXH %>% 
  mutate(total = n()) %>%
  dplyr::group_by(TRANWORK)%>%
  dplyr::summarize(count=n())
```

### Pulling in 2019 data as comparison

```{r}
ddi <- read_ipums_ddi("usa_00011.xml") # downloaded April 10 2023
data <- read_ipums_micro(ddi) # 126623 observations before any filtering

# same sample but with 150+ variables. 
# NEED TO CHANGE XML file that referneces the data file. currently says usa_00011.dat.gz so these two lines of code do not work. 
#ddi <- read_ipums_ddi("C:/Users/aleaw/Box/Fiscal Futures/FY22_Working/WFH/Data/IL_2021_1yrACS_datDDI.xml") # downloaded April 10 2023
#data <- read_ipums_micro(ddi) # 126623 observations before any filtering

data <- data %>% select(INCEARN, INCWAGE, INCTOT, TRANWORK, OCCSOC,CLASSWKR, EMPSTAT, LABFORCE, PERWT, COUNTYFIP, PUMA, PWSTATE2, AGE, STRATA, CLUSTER, RACE, SEX )



# replaces 0 with NA for variables listed. Allows topline to calculate "Valid Percent" when it recognizes missing values

data <- data %>% replace_with_na(replace = list(
  EMPSTAT= c(0), 
  LABFORCE=c(0), 
  CLASSWKR = c(0),
  OCCSOC = c(0),
  TRANWORK = c("N/A","0")))
```

# Alea dwelling on which observations to include

126,623 observations originally in ACS 2021 1-year sample.

-   63,453 obs in labor force

    -   Survey question asks if they have worked during the last week. So they could be recently unemployed and still have earned income that year and

-   63,113 observations have earned incomes (`incearn`)\> \$0.

How many people are in labor force and have incomes of zero or less than zero? (In the Labor force = EMPSTAT employed(1)+unemployed(2)

-   41,289 observations are not in the labor force.

    -   41,275 observations are not in the labor force and have INCEARN values equal to 0. Drop from sample.

    -   3,829 observations are not in the labor force but have INCEARN values greater than zero. They also have OCCSOC codes. Let's keep them in sample. for now.

Should they be removed right away?

```{r reloading-sampledata}

ddi <- read_ipums_ddi("usa_00011.xml") # downloaded April 10 2023
data <- read_ipums_micro(ddi) # 126623 observations before any filtering

data <- data %>% select(INCEARN, INCWAGE, INCTOT, TRANWORK, OCCSOC,CLASSWKR, EMPSTAT, LABFORCE, PERWT, COUNTYFIP, PUMA, PWSTATE2, AGE, STRATA, CLUSTER, RACE, SEX )

data <- data %>% replace_with_na(replace = list(
  EMPSTAT= c(0), 
  LABFORCE=c(0), 
  CLASSWKR = c(0),
  OCCSOC = c(0),
  TRANWORK = c("N/A","0")))

# data %>% filter(INCEARN > 0) 
# 63,113 observations have incomes greater than zero
# data %>% filter(INCEARN >= 0) 
# 126,570 obs are > or = to 0 (almost all obs, not useful)
# data %>% filter(INCEARN >= 0 & EMPSTAT == 1)  
# 59,221 are in labor force and have earned income values >= $0
# data %>% filter(INCEARN >= 0 & EMPSTAT == 1)  
# data %>% filter(INCEARN > 0 & EMPSTAT == 1)  
# 59,214 obs in labor force and have income greater than $0.
# ^ These are our main sample observations before 

table(data$LABFORCE)
#63,453 obs in labor force (LABFORCE ==2)

table(data$EMPSTAT)
# 59,259 obs are employed (EMPSTAT == 1)
# 41,289 obs are not in labor force (EMPSTAT == 3)


# how many are not in labor force but had personal earned income values?
data %>% 
  filter(EMPSTAT == 3 & 
           INCEARN > 0) 
# 3,879 observations have INCEARN data but are not in the labor force. 


# who is not in labor force but has earned income greater than zero? 
# do they have occupation codeS?
data %>% 
  filter(EMPSTAT == 3 & INCEARN >0) %>% 
  group_by(OCCSOC) %>% 
  summarize(count = n())
# they all have occupation codes. Lets keep them in our sample. 



#### LABOR FORCE & EARNED INCOME (EMPSTAT & INCEARN) ####
# 1 is employed, 2 is unemployed
# 3 is not in labor force
# 0 is missing value

data %>% 
  filter(INCEARN> 0) %>% 
  group_by(EMPSTAT) %>% 
  summarize(count = n())

data %>% 
  filter(INCEARN == 0) %>% 
  group_by(EMPSTAT) %>% 
  summarize(count = n())
# only 7 observations are considered employed and have a incearn == 0. That's good. 
# 2,173 had earned incomes of 0 and were unemployed but in the labor force. Makes sense.

# 37,396 obs were not in labor foce and had earned incomes of zero. Makes sense. 
#### ^ These observations should be dropped from sample. #### 

data %>% 
  filter(INCEARN < 0) %>% 
  group_by(EMPSTAT) %>% 
  summarize(count = n()) %>% 
  arrange(desc(count))

## Very few observations have incearned less than zero. 
## Let's drop INCEARN <0 from sample. 
```

::: {.callout-important icon="false"}
## Drop observations?

1.  37,396 observations have earned incomes = \$0 and they are not in the labor force.
2.  21,881 observations are missing income values for `incearn`
3.  53 observations have earned incomes \< \$0.

They should all be dropped, right??
:::

```{r dropping-obs, eval=FALSE}
#Do any observations have missing values for incearn but values for inctot?

#48,056 observations have total income values > $0 but earned income values = $0. retired people with SSI? 

#How many of 48,056 are in labor force?…. 
# Only 7. So don't worry about it. 
data %>% filter(INCEARN == 0 & 
                  INCTOT > 0 &
                  EMPSTAT == 1
                )

data %>% 
  filter(EMPSTAT == 3) %>%  
  # 41,289 observations are NOT in the labor force. 
  summarize(count = n())

data %>% 
  filter(EMPSTAT == 3 & OCCSOC >0) %>%  
  # 12,656 observations are NOT in the labor force but they DO have occupation codes. 
  summarize(count = n())

data %>% 
  filter(EMPSTAT == 2 & OCCSOC >0) %>%  
  summarize(count = n())
  # 4,194 observations are unemployed but they DO have occupation codes. 
  # ACS question asks if they worked the last week. 
  # Could be recently unemployed but still have useful info. Keep in sample?


data %>% 
  filter(EMPSTAT == 3 & OCCSOC >0) %>%  
  summarize(count = n())
# 12,656 are not in labor force but have occupation codes
# remember, if not in labor force, ACS uses occupation that they had in the last 5 years
# drop from sample. We are interested in workers with data who worked in 2021. 
```

::: callout-note
## Why don't we care about younger workers?

Are we still using the 25-64 age range for our sample? Pros and cons of including/excluding?

-   Pro: Other literature used same age range

-   Con: Smaller sample. Loss of potentially interesting information on younger workers.
:::

If the sample keeps only individuals between the ages of 25 and 65, sample size goes from over 126,623 observations to around 65,000 observations. BUT many of these observations may not include income data or other important variables in the responses. Only 50,817 observations were in the labor force and between those ages. 50,993 observations are 25-65 with incomes \> \$0. The sample size is shrinking quickly.....

```{r eval=FALSE}
data25to64 <- data %>% 
  filter(AGE > 24 & AGE < 65)
# 65,675 observations in age range
# in actual analysis, do NOT exclude observations this way. Changings population size and changes all  error calculations.

# data25to64 %>% filter(INCEARN >0)
# 50,993 observations with earned income > $0

```

### Labor Force Variables

`OCC2010` is a harmonized occupation coding scheme as broad groups. These are 4 characters long and are the first 4 characters of the longer ONET & SOC codes.

`OCCSOC` is 6 digits long. It is the first 6 digits of 8-digit ONET code.

-   In some cases the SOC occupation codes are aggregated if they do not have an exact match to a Census occupation code or to preserve confidentiality in cases where the category contained fewer than 10,000 people nationwide.

`LABFORCE` for if in labor force. 1 = not in labor force, 2 = in labor force, 0 is NA

`EMPSTAT` and `EMPSTATD` for employment status (simple and the detailed version). 1=employed, 2=unemployed, 3=not in labor force for empstat, 0 is NA

-   for those who are unemployed, data refers to most recent job if it was within the last 5 years.

`CLASSWKRD` might be useful. Contains info on self-employed, wages, salary, etc for class of worker.

IPUMS OCC codes over time [link](https://usa.ipums.org/usa/volii/occsoc18.shtml)

```{r worker-descstats, eval=FALSE}
# Employment Status
table(data$EMPSTAT) # unweighted

data %>% 
  group_by(as_factor(EMPSTAT)) %>%
  dplyr::summarize(weightedcount=sum(PERWT),
                   unweightedcount = n()) %>%  #weighted
  mutate(pct_weight = weightedcount/sum(weightedcount),
         pct_noweight = unweightedcount/sum(unweightedcount))

topline(data, EMPSTAT, PERWT)

# Labor Force
data %>% 
  group_by(as_factor(LABFORCE)) %>%
  dplyr::summarize(weightedcount=sum(PERWT),
                   unweightedcount = n()) %>%  #weighted
  mutate(pct_weight = weightedcount/sum(weightedcount),
         pct_noweight = unweightedcount/sum(unweightedcount))


# Class of Worker
data %>% 
  group_by(as_factor(CLASSWKR)) %>%
  dplyr::summarize(weightedcount=sum(PERWT),
                   unweightedcount = n()) %>%  #weighted
  mutate(pct_weight = weightedcount/sum(weightedcount),
         pct_noweight = unweightedcount/sum(unweightedcount))
# data %>% 
#   group_by(as_factor(TRANWORK)) %>%
#   dplyr::summarize(weightedcount=sum(PERWT),
#                    unweightedcount = n()) %>%  #weighted
#   mutate(pct_weight = weightedcount/sum(weightedcount),
#          pct_noweight = unweightedcount/sum(unweightedcount))

data <- data %>% 
  mutate(did_wfh = if_else(TRANWORK==80, 1,2)) # 1 = wfh, 2 = did not wfh
# 10,949 observations worked from home
# 47,584 did not work from home.
#table(data$did_wfh)
topline(df = data, variable = did_wfh, weight = PERWT)

topline(df = data, variable = LABFORCE, weight = PERWT )


```

[***Unweighted***]{.underline} *-*

*EMPSTAT: 59,259 observations are employed, 4,194 unemployed observations, and 41,289 observations are not in the workforce (21,881 NAs)*

*LABFORCE: 63,453 are in labor force, 41,289 are not. (21,881 NAs)*

*CLASSWKR: Of these, 68,388 work for wages and 7183 people are self-employed. (51,052 NA)*

*`did_wfh`: 10,949 observations worked from home, 47,584 did not work from home. Based on TRANWORK variable: recoded as binary variable (either did wfh or did not wfh).*

[**Weighted**]{.underline} **-**

EMPSTAT: 6,102,522 people are employed (49%), 479,879 people are unemployed (3.8%), and 3,624,811 are not in the labor force (29%). There are 2,463,257 missing values; Same as LABFORCE.

LABFORCE: 6,582,401 people (52%) are in the labor force. 3,625,811 (28%) of people are not in the labor force. 2,463,257 (20%) of observations missing values.

-   employed and unemployed equal number of people in labor force - that's good

`did_wfh`: 19.2% did work from home and 80.8% did not work from home in Illinois (when not filtering for age or employment)

Location of primary workplace: 5.8 million people located in Illinois.

::: {.callout-note icon="false"}
## To Do: Compare summary tables and output from individual data

Compare average income for counties in Illinois to Summary tables from Census.
:::

For the counties that can be identified in the data (populations \> 100,000 & \< 200,000. 1-Year ACS have minimum of 65,000 population), the census summary tables are close but not identical to the tables calculated with the ACS sample data. "In this way more densely populated areas, like Chicago and Cook County will contain many PUMAs within their boundaries, while multiple sparsely populated entire counties, e.g., Jackson, Perry, Franklin, and Williamson, will comprise one PUMA." - [IPUMS v other Geographies](https://iecam.illinois.edu/browse/about-public-use-microdata-areas-pumas#:~:text=What%20is%20a%20PUMA%3F,Community%20Survey%201%2Dyear%20estimates)

```{r summarytable-check}

data %>% 
  group_by(as_factor(EMPSTAT), COUNTYFIP) %>%
  dplyr::summarize(weightedcount=sum(PERWT),
                   unweightedcount = n()) %>%  #weighted
  mutate(pct_weight = weightedcount/sum(weightedcount),
         pct_noweight = unweightedcount/sum(unweightedcount))

crosstab(data, COUNTYFIP, EMPSTAT, weight=PERWT)
```

19 is Champaign, 31 is Cook, 37 is DeKalb, 43 is DuPage, 89 is Kane, 111 is McHenry, etc.

Economic Characteristics summary table: [link](https://data.census.gov/table?t=Employment&g=040XX00US17,17$0500000&tid=ACSDP1Y2021.DP03&moe=false&tp=false)

### Income deciles

```{r warning=FALSE, message=FALSE}


summary(as.numeric(data$INCEARN))

# we want positive income values
data <- data %>% 
  filter(INCEARN>0 
       #  & INCWAGE != 999999 & INCWAGE != 999998
       # 999999 is missing values for the WAGE variable
         ) #  %>% filter(AGE > 25)
# 104,689 obs remaining if >=0
# 65113 obs if > 0
# 55332 observations if also older than 25



summary(as.numeric(data$INCEARN))

```

> When filtering for ages greater than 25, observations go from \~65,000 to \~55,000. Do we want to drop this age group? Are we not interested in younger workers? I don't think we should drop any age of workers...

After dropping income values below zero, the median earned income is 40,000. According to the census website, the per capita earned income is \$39,571. That seems like a good sign?

```{r message=FALSE, warning=FALSE}
telework <- telework %>% 
  mutate(CanWorkFromHome = case_when(
  teleworkable == 0 ~ "No WFH",
  teleworkable < 1 ~ "Some WFH",
  teleworkable == 1 ~ "Can WFH",
  TRUE ~ "Check Me")
)
table(telework$CanWorkFromHome)
  
# causes problems for any occupation code that has XX in it!! 
#data2$OCCSOC_num <- as.numeric(data2$OCCSOC)

joined<-left_join(dataXH, telework, by = c("OCCSOC"= "occ_codes"))

summary(joined$teleworkable)
# teleworkable values are an average of occupations with same first 5 digits and first 4 digits.


joined %>% 
  filter(CanWorkFromHome == "Some WFH") %>% 
  distinct(OCCSOC)

#joined %>% arrange(INCEARN)

#library(srvyr)
#as_survey() from srvyr package

dstrata <- joined %>% as_survey(strata = STRATA , weights = PERWT)

inc_quantiles<-survey::svyquantile(~INCEARN, design=dstrata, 
                    quantiles = c(0, 0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1) ,
                    #interval.type = "quantile",
                    na.rm=TRUE, 
                    ci = FALSE 
                    )
inc_quantiles

dstrata <- dstrata %>% 
  mutate(percentile = ntile(INCEARN, 100),
         decile = ntile(INCEARN, 10)
         ) 

dstrata %>%
          group_by(decile) %>% 
  summarize(min = min(INCEARN),
            max=max(INCEARN),
            avg_income = mean(INCEARN),
            average_income = survey_mean(INCEARN),
            pop_represented = sum(PERWT),
            obs_count = n())


# no weights comparison
data %>%
  mutate(
        decile = ntile(INCEARN, 10)
         ) %>%
          group_by(decile) %>%
  summarize(min = min(INCEARN),
            max=max(INCEARN),
            avg_income = mean(INCEARN),
            pop_represented = sum(PERWT),
            obs_count = n())



breaks2 <- c(5400, 14000, 23400, 31200, 40000, 50000, 65000, 84000, 115000)


```

```{r}

summary <- dstrata %>% 
  #filter(EMPSTAT != 3)%>%
  mutate(percentile = ntile(INCEARN, 100),
         decile = ntile(INCEARN, 10)
         ) %>%
  group_by(decile) %>% 
  summarize(min = min(INCEARN),
            max=max(INCEARN),
            avg_income = mean(INCEARN),
            average_income = survey_mean(INCEARN),
            pop_represented = sum(PERWT),
            obs_count = n())

sum(summary$pop_represented) #6.67 when only wages > $0 are filtered for
sum(summary$obs_count)
summary 

summary %>% 
  ggplot(aes(x=decile, y=average_income)) + 
  geom_col()


dstrata %>% 
  as_data_frame()%>% 
  ggplot(aes(x=decile)) + 
  geom_bar(aes(fill=CanWorkFromHome), position="dodge") + 
  labs(title = "Count of observations")


dstrata %>% 
  as_data_frame()%>% 
  ggplot(aes(x=decile)) + 
  geom_bar(aes(y = (..count../sum(..count..)), fill=CanWorkFromHome), position="dodge")+
  labs(title = "Percent of observations")



dstrata %>% 
  as_data_frame()%>% 
  ggplot(aes(x=decile, y = (..count..)/sum(..count..)*10, fill = CanWorkFromHome)) + 
  #geom_bar(aes(fill=CanWorkFromHome), position="dodge")+
    geom_bar(aes(fill = CanWorkFromHome), position = "dodge") +

  coord_flip()+   #geom_text(aes(y = ((..count..)/sum(..count..)), label = scales::percent((..count..)/sum(..count..))), stat = "count", vjust = -0.25) +
     # scale_y_reverse(limits = rev)+

  scale_x_discrete(limits = c("Bottom 10%", "20%", "30%", "40%", "50%", "60%", "70%", "80%", "90%", "Top 10%"))+ 
  scale_y_continuous(labels = scales::percent)+
  theme(legend.position = "bottom") +
  labs(title = "Able to work from home by income decile", 
       y = "Percent of Workers in each Income Decile",
       x = "",
       caption = "n = 65,113 observations in 2021 1-year sample. 
       Represents the 6.67 million people in Illinois' workforce with earned income > $0.")


dstrata %>% 
  as_data_frame() %>% 
#  mutate(ypct = (..count../sum(..count..)*10)) %>%
  ggplot(aes(x=decile, y = (..count../sum(..count..)*10), fill = CanWorkFromHome) )+ 
  geom_bar(aes(fill=CanWorkFromHome), position="dodge")+

  scale_x_discrete(limits = c("Bottom 10%", "20%", "30%", "40%", "50%", "60%", "70%", "80%", "90%", "Top 10%"))+ 
  theme(legend.position = "bottom") +
  scale_y_continuous(labels = scales::percent)+
  labs(title = "Same graph but flipped axes: 
       Able to work from home by income decile", 
       y = "Percent of Workers in each Income Decile") 
```

```{r incearn-descripstats, warning=FALSE, message=FALSE}

summary(as.numeric(data$INCTOT))
summary(as.numeric(data$INCEARN))

attributes(data$INCTOT)
attributes(data$INCEARN)


```

#### INCWAGE vs INCEARN vs INCTOT deciles

Look at decile breaks for **INCWAGE** and **INCEARN**: THESE ARE NOT WEIGHTED in this comparison.

```{r}
data2 <- data %>% filter(OCCSOC != 0) # none are dropped


### WAGES - not weighted ####
income_deciles <- data2 %>% 
  filter(INCWAGE > 0) %>%
  group_by(ntile(INCWAGE, 10)) %>%
  dplyr::summarize(mean_inc = mean(INCWAGE),
                   decile_min = min(INCWAGE),
            decile_max = max(INCWAGE)
            ) 

income_deciles # WAGES 

data2 %>% 
  group_by(ntile(INCWAGE,10)) %>%
  dplyr::summarize(mean_inc = mean(as.numeric(INCWAGE)) )%>%
  ungroup() %>%
  mutate(INCWAGE_decile='ntile(INCWAGE,10)') %>%
  ggplot(aes(x = ntile(INCWAGE_decile,10), y=mean_inc)) + 
  geom_bar(stat = "identity") +
  labs(x="Income decile", y="Mean Income from WAGES", title = "Average Income for each Income Decile WAGES ONLY.") +
  scale_x_continuous(breaks = 1:10)



### INCEARN ###
income_deciles <- data2 %>% 
  filter(INCEARN > 0) %>%
  group_by(ntile(INCEARN, 10)) %>%
  dplyr::summarize(mean_inc = mean(INCEARN),
                   decile_min = min(INCEARN),
            decile_max = max(INCEARN)
            ) 

income_deciles

data2 %>% 
  group_by(ntile(INCEARN,10)) %>%
  dplyr::summarize(mean_inc = mean(as.numeric(INCEARN)) )%>%
  ungroup() %>%
  mutate(INCEARN_decile='ntile(INCEARN,10)') %>%
  ggplot(aes(x = ntile(INCEARN_decile,10), y=mean_inc)) + 
  geom_bar(stat = "identity") +
  labs(x="Income decile", y="Mean Income", title = "Average Income for each Income Decile using INCEARN.") +
  scale_x_continuous(breaks = 1:10)


### INCTOT ###
income_deciles <- data2 %>% 
  filter(INCTOT > 0 & INCTOT < 9999998) %>%
  group_by(ntile(INCTOT, 10)) %>%
  dplyr::summarize(mean_inc = mean(INCTOT),
                   decile_min = min(INCTOT),
            decile_max = max(INCTOT)
            ) 

income_deciles
```

### Occupation codes & teleworkability

Old files:

-   teleworkable2010.csv has the 6digit OCCSOC codes. I also added the 5 digit broader version that ends with a 0 in the 6th digit to increase the chances of matching.

-   Updated teleworkable2010.csv again with 4digitXX codes and 5digitXcodes to increase matching.

-   `teleworkable2018onward.csv` has all codes (2010, 2019 transition, & new 2018 codes).

-   renamed teleworkable_AWM.csv and has NA values added for 0's and unemployed code to help matching

```{r}

# noOCCSOC<- data %>% 
#   filter(OCCSOC == 0) #98205 with occsoc=0
# 
# table(noOCCSOC$EMPSTAT)
# 
# before filtering out the incwage and inctot variables for 0's and negatives, 
# #98% of the people without Occupation codes are not in the labor force. Makes sense
# all observations have occsoc codes after filtering for INCWAGE and INCTOT and previous steps


topline(df = data, variable = EMPSTAT, weight = PERWT )

sum(data$PERWT) # 6.67 million people represented by remaining observations in sample


joined %>% count()

g <- ggplot(joined, aes(INCEARN))

g + geom_bar(width=10000)

g + geom_bar(aes(weight = PERWT),width=10000)


sum(joined$PERWT)


```

```{r}
dstrata <- joined %>% as_survey(strata = STRATA , weights = PERWT)

dstrata <- dstrata %>% 
  mutate(decile = ntile(INCWAGE, 10)
         ) 


summary <- dstrata %>% 
  #filter(EMPSTAT != 3)%>%
  mutate(
         decile = ntile(INCWAGE, 10)
         ) %>%
  group_by(decile) %>% 
  summarize(min = min(INCWAGE),
            max=max(INCWAGE),
            avg_income = mean(INCWAGE),
            average_income = survey_mean(INCWAGE),
            pop_represented = sum(PERWT),
            obs_count = n())

sum(summary$pop_represented)
sum(summary$obs_count)

dstrata %>% 
  as_data_frame()%>% 
  ggplot(aes(x=decile, y = (..count..)/sum(..count..)*10, fill = CanWorkFromHome)) + 
  #geom_bar(aes(fill=CanWorkFromHome), position="dodge")+
    geom_bar(aes(fill = CanWorkFromHome), position = "dodge") +

  coord_flip()+ 

  scale_x_discrete(limits = c("Bottom 10%", "20%", "30%", "40%", "50%", "60%", "70%", "80%", "90%", "Top 10%"))+ 
  scale_y_continuous(labels = scales::percent)+
  theme(legend.position = "bottom") +
  labs(title = "Ability to Work from Home based on Occupation Characteristics", x = "Income decile from WAGES, All Ages", caption= "Based on D&N teleworkable categorization and expanded for new 2018 SOC OCC codes.")

  
dstrata <- joined %>% 
  filter(AGE > 25 & AGE < 65) %>% 
  as_survey(strata = STRATA , weights = PERWT)

dstrata <- dstrata %>% 
  mutate(decile = ntile(INCWAGE, 10)
         ) 

dstrata %>% 
  as_data_frame()%>% 
  ggplot(aes(x=decile, y = (..count..)/sum(..count..)*10, fill = CanWorkFromHome)) + 
  #geom_bar(aes(fill=CanWorkFromHome), position="dodge")+
    geom_bar(aes(fill = CanWorkFromHome), position = "dodge") +

  coord_flip()+   #geom_text(aes(y = ((..count..)/sum(..count..)), label = scales::percent((..count..)/sum(..count..))), stat = "count", vjust = -0.25) +
     # scale_y_reverse(limits = rev)+

  scale_x_discrete(limits = c("Bottom 10%", "20%", "30%", "40%", "50%", "60%", "70%", "80%", "90%", "Top 10%"))+ 
  scale_y_continuous(labels = scales::percent)+
  theme(legend.position = "bottom") +
  labs(title = "Ability to Work from Home based on Occupation Characteristics", x = "Income decile from WAGES, 25-65", caption= "Based on D&N teleworkable categorization and expanded for new 2018 SOC OCC codes.")

dstrata %>% 
  as_data_frame()%>% 
  ggplot() + 
  geom_bar(aes(x=ntile(INCWAGE,10), fill = CanWorkFromHome), position = "dodge") +
  labs(title = "Ability to Work from Home based on Occupation Characteristics", x = "Income decile from WAGES", caption= "Based on D&N teleworkable categorization and expanded for new 2018 SOC OCC codes")

## OLD JOINING NOTES## 
#innerjoined<-inner_join(data2, telework, by = c("OCCSOC_num"= "BroadGroupCode"))

#leftjoined<-left_join(data2, telework, by = c("OCCSOC_num"= "BroadGroupCode"))
# keeps all observations in data 2 even if they don't match

#antijoin <-anti_join(data2, telework, by = c("OCCSOC_num"= "onetsoc_6digits"))
# 158525. Many were aggregated to 5digits with 6digit as 0.
# 91403 obs after updating teleworkable file to 5digits with 6digit as 0

#couldnt use _num version due to XX in values.
#antijoin <-anti_join(data2, telework, by = c("OCCSOC"= "onetsoc_6digits"))
# 50,659 obs after adding 5digitsX and 4digitsXX and 5digits with sixth as 0 to csv file

#unique(antijoin$OCCSOC) #121 unique codes did not match.
# down to 67 after adding 5digitsX and 4digitsXX and 5digits with sixth as 0 to csv file

#joined <- joined %>% mutate(occsoc5digits = substr(OCCSOC,1,5))
#table(joined$occsoc5digits)


#table(joined$Teleworkable)
```

**OCC2010 variable labels:**

From DDI on IPUMS download: https://live.usa.datadownload.ipums.org/web/extracts/usa/1985137/usa_00006.xml#OCC

Management, Business, Science, and Arts = 10-430\
Business Operations Specialists = 500-730\
Financial Specialists = 800-950\
Computer and Mathematical = 1000-1240\
Architecture and Engineering = 1300-1540\
Technicians = 1550-1560\
Life, Physical, and Social Science = 1600-1980\
Community and Social Services = 2000-2060\
Legal = 2100-2150\
Education, Training, and Library = 2200-2550\
Arts, Design, Entertainment, Sports, and Media = 2600-2920\
Healthcare Practitioners and Technicians = 3000-3540\
Healthcare Support = 3600-3650\
Protective Service = 3700-3950\
Food Preparation and Serving = 4000-4150\
Building and Grounds Cleaning and Maintenance = 4200-4250\
Personal Care and Service = 4300-4650\
Sales and Related = 4700-4965\
Office and Administrative Support = 5000-5940\
Farming, Fishing, and Forestry = 6005-6130\
Construction = 6200-6765\
Extraction = 6800-6940\
Installation, Maintenance, and Repair = 7000-7630\
Production = 7700-8965\
Transportation and Material Moving = 9000-9750\
Military Specific = 9800-9830\
Unemployed (no occupation for 5+ years) or Never Worked = 9920\

## PUMAs and Shapefiles

PUMAs contain around 100,000 people.

For the counties that can be identified in the data (populations \> 100,000 & \< 200,000. 1-Year ACS have minimum of 65,000 population), the census summary tables are close but not identical to the tables calculated with the ACS sample data. "In this way more densely populated areas, like Chicago and Cook County will contain many PUMAs within their boundaries, while multiple sparsely populated entire counties, e.g., Jackson, Perry, Franklin, and Williamson, will comprise one PUMA." - [IPUMS v other Geographies](https://iecam.illinois.edu/browse/about-public-use-microdata-areas-pumas#:~:text=What%20is%20a%20PUMA%3F,Community%20Survey%201%2Dyear%20estimates)

```{r summarytables-check}

dataXH %>% 
   group_by(as_factor(EMPSTAT), COUNTYFIP) %>% 
   dplyr::summarize(weightedcount=sum(PERWT), unweightedcount = n()) %>% #weighted 
   mutate(pct_weight = weightedcount/sum(weightedcount), 
          pct_noweight = unweightedcount/sum(unweightedcount)) 
 
crosstab(data, COUNTYFIP, EMPSTAT, weight=PERWT)
```

19 is Champaign, 31 is Cook, 37 is DeKalb, 43 is DuPage, 89 is Kane, 111 is McHenry, etc.

Economic Characteristics summary table: [link](https://data.census.gov/table?t=Employment&g=040XX00US17,17$0500000&tid=ACSDP1Y2021.DP03&moe=false&tp=false)

```{r warning = FALSE, message=FALSE, results='hide'}


# PUMA shapefiles
pumasIL <- pumas("IL", cb=T, year=2019)
#county shapefiles
countyIL <- counties("IL", cb=T, year=2019)

#pumasdf <- fortify(pumasIL, region = 'PUMACE10')
```

```{r warning = FALSE, message=FALSE}

pums_weighted <- data %>% 
  filter(INCEARN>0)%>%
  group_by(PUMA, COUNTYFIP) %>% 
  summarize(weighted_obs = sum(PERWT),
            pct_telework = mean(teleworkable),
            pct_didwfh = mean(did_wfh),
            observs = n(),
            avg_inc = mean(INCEARN),
            avg_inc_w = mean(INCEARN, weight = PERWT)) %>%  #number of people the sample represents
  mutate(PUMA = str_pad(PUMA, 5, pad="0"),
         countyFIP = str_pad(COUNTYFIP, 3, pad = "0"))

pums_unweight <- data %>% 
  group_by(PUMA, COUNTYFIP) %>% 
  summarize(unweight = n()) %>% #unweighted number of observations
  mutate(PUMA = str_pad(PUMA, 5, pad="0"),
         countyFIP = str_pad(COUNTYFIP, 3, pad = "0"))

plotweighted <- pumasIL %>% 
  left_join(pums_weighted, by = c("PUMACE10" = "PUMA"))

plotunweight <- pumasIL %>% 
  left_join(pums_unweight, by = c("PUMACE10" = "PUMA"))

plot(plotweighted["weighted"])

plot(plotweighted["avg_inc"])
plot(plotweighted["avg_inc"])


plot(plotunweight["unweight"])

FIPweighted <- countyIL %>% left_join(pums_weighted, by = c("COUNTYFP" = "countyFIP"))
FIPunweight <- countyIL %>% left_join(pums_unweight, by = c("COUNTYFP" = "countyFIP"))
plot(FIPweighted["weighted"])
plot(FIPunweight["unweight"])


plot(countyIL["COUNTYFP"])


```

Observations using `CITY` variable: identifies observations from Chicago.

88 distinct PUMA areas.

```{r}
data %>% group_by(CITY) %>% distinct(CITY)
data %>% group_by(PUMA) %>% summarize(observs = n())
data %>% filter(INCEARN > 0) %>% group_by(PUMA) %>% summarize(observs = n())

data %>% group_by(COUNTYFIP, PUMA) %>% summarize(observs = n())

data %>% 
  group_by(COUNTYFIP, PUMA) %>% 
  summarize(observs = n(),
            avg_inc = mean(INCEARN),
            avg_inc_w= mean(INCEARN, weight = PERWT))
```

#### PUMAS vs COMMZONE vs COUNTIES

[Link from Francis on COMZONE variable](https://eig.org/the-uneven-geography-of-remote-work/) (Commuter Zones)

[Interactive ESRI Map of all PUMA outlines](https://univofillinois.maps.arcgis.com/apps/mapviewer/index.html?layers=71eb4ef236ca42c4b577a0a105e790e2)

[Article on calculating mean income for groups of geographies with ACS data](https://atcoordinates.info/2019/05/13/calculating-mean-income-for-groups-of-geographies-with-census-acs-data/)

```{r stateworkedin}
# State worked in:
#0=NA, 17=Illinois



# ipums_var_desc(data, PWSTATE2)

data <- data %>% 
  mutate(PWSTATE2_clean = as_factor(lbl_na_if(PWSTATE2, ~.val %in% c(0))))

data %>% 
  group_by(PWSTATE2) %>%
  dplyr::summarize(n=sum(PERWT)) %>% #number of people that match that observation
  mutate(pct = n/sum(n)) %>% 
  arrange(desc(pct))
```

# Other Sources and Papers

Ability to work from home: evidence from two surveys and implications for the labor market in the COVID-19 pandemic. June 2020. [BLS Monthly Labor Review](https://www.bls.gov/opub/mlr/2020/article/ability-to-work-from-home.htm)

-   Authors used Current Population Survey data and O\*NET job-content data to categorize jobs as able or unable to telework. Followed Dingel & Neiman's methodology of classifying telework feasibility and merging with data from American Time Use Survey (ATUS)

-   Compares ability to work from home with actual occurance of working from home based on American Time Use Survey and Occupational Information Network (O\*NET). Also uses Current Population Survey data to look at how effects differed between occupations where telework was feasible or not.

# Srvyr and survey packages

notes to myself on the two options for survey data and syntax

## survey() package

```{r eval=FALSE}
survey::svydesign()

svy <- svydesign(~CLUSTER, weights = ~PERWT, strata = ~STRATA, data = data, nest = TRUE, check.strata = FALSE)

svymean(~EMPSTAT, svy)
```

## srvyr() package

```{r eval= FALSE}

srvyr::as_survey_design(strata = _, weights = __)

svy <- as_survey(data, ids = CLUSTER, weights = PERWT, strata = STRATA, nest = TRUE)

summarize(svy, HISPAN = survey_mean(HISPAN))

```
